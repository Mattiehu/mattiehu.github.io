<!DOCTYPE html>

<html>

<head>

<title>Mattie Hu's MEDPL150 page</title>

</head>

<body>

<h1>Susan Sontag's photogrphy</h1>

  In her article “‘With ‘AI slop’ distorting our reality, the world is sleepwalking into disaster” Nesrine Malik talks about how generative AI changes the way we see things, use media, and understand the world. She calls some content “AI Slop.” This means many low-quality and cheap images made by machines. These images look strange or political. Some are fun to look at, but they do not teach anything. Malik says this content is not only annoying, but also dangerous. It changes the way people understand the world. It also makes it harder to know what is real.

Malik says AI slop creates a second visual reality. This reality is hard to tell apart from the real world, especially on social media. The systems that show these images do not know what is true or false. They do not know what is a joke or what is propaganda. They only show content that makes people look at it or click. So shocking AI images spread very fast. At the same time, careful reporting with facts is ignored. The platforms that show this content benefit. Cheap machine-made images save money. They also keep people scrolling, even if people start to trust what they see less.

She also says these images carry ideas and values. Many of them show old-fashioned or backward values. They show white families in traditional roles. They show women mainly taking care of the home. They show general ideas about “tradition” that match conservative thinking. These biases are not made on purpose. They come from the information used to teach AI. The information itself already has unfair ideas and cultural stereotypes. AI repeats these values. It also makes them seem new or fun when it shares them again.

Malik explains that AI slop is not only on public websites. It is also in private spaces. It spreads in WhatsApp groups, Telegram chats, and other closed digital spaces. In these spaces, people rarely check facts. People trust the sender, so they accept the images quickly. Over time, all this content can confuse people. It can make them tired or not care. People cannot tell what is real and what is made by machines. They start to separate from politics and society.

Malik makes her point strong because she says AI slop is not just a problem in the future. It is already part of daily life. People see these images every day. They share them without thinking. They accept the ideas in them without question. The content changes how people look at the world. It also changes how people trust what they see. People see more images from machines, and less from careful reporting.

This article helps readers understand that AI slop is everywhere. It is in social media, messaging apps, and websites. It is cheap, easy to make, and often fun to look at. It also carries old ideas and shows biased values. It spreads quickly, and people do not always know what is true. The problem is not only the images. The problem is how these images change the way people think and feel. They can make people less aware of reality and less careful about truth.</p>
<br>
<a href="index.html"> Back to homepage </a>

</body>

</html>
